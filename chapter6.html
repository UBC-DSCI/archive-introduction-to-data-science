<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Introduction to Data Science</title>
  <meta name="description" content="This is an open source textbook for teaching Introductory Data Science.">
  <meta name="generator" content="bookdown 0.7 and GitBook 2.6.7">

  <meta property="og:title" content="Introduction to Data Science" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is an open source textbook for teaching Introductory Data Science." />
  <meta name="github-repo" content="UBC-DSCI/introduction-to-data-science" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Introduction to Data Science" />
  
  <meta name="twitter:description" content="This is an open source textbook for teaching Introductory Data Science." />
  

<meta name="author" content="Tiffany Timbers">
<meta name="author" content="Matías Salibián-Barrera">
<meta name="author" content="Bruce Dunham">
<meta name="author" content="Melissa Lee">
<meta name="author" content="Samuel Hinshaw">


<meta name="date" content="2018-05-31">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="chapter5.html">
<link rel="next" href="chapter7.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script src="libs/htmlwidgets-1.2/htmlwidgets.js"></script>
<script src="libs/plotly-binding-4.7.1/plotly.js"></script>
<script src="libs/typedarray-0.1/typedarray.min.js"></script>
<link href="libs/crosstalk-1.0.0/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk-1.0.0/js/crosstalk.min.js"></script>
<link href="libs/plotlyjs-1.29.2/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotlyjs-1.29.2/plotly-latest.min.js"></script>


<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Introduction to Data Science</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introductory Data Science</a></li>
<li class="chapter" data-level="2" data-path="chapter2.html"><a href="chapter2.html"><i class="fa fa-check"></i><b>2</b> Introduction to Data Science</a><ul>
<li class="chapter" data-level="2.1" data-path="chapter2.html"><a href="chapter2.html#overview"><i class="fa fa-check"></i><b>2.1</b> Overview</a></li>
<li class="chapter" data-level="2.2" data-path="chapter2.html"><a href="chapter2.html#learning-objectives"><i class="fa fa-check"></i><b>2.2</b> Learning Objectives</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="chapter3.html"><a href="chapter3.html"><i class="fa fa-check"></i><b>3</b> Reading in data locally and from the web</a><ul>
<li class="chapter" data-level="3.1" data-path="chapter3.html"><a href="chapter3.html#overview-1"><i class="fa fa-check"></i><b>3.1</b> Overview</a></li>
<li class="chapter" data-level="3.2" data-path="chapter3.html"><a href="chapter3.html#learning-objectives-1"><i class="fa fa-check"></i><b>3.2</b> Learning Objectives</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="chapter4.html"><a href="chapter4.html"><i class="fa fa-check"></i><b>4</b> Cleaning and wrangling data</a><ul>
<li class="chapter" data-level="4.1" data-path="chapter4.html"><a href="chapter4.html#overview-2"><i class="fa fa-check"></i><b>4.1</b> Overview</a></li>
<li class="chapter" data-level="4.2" data-path="chapter4.html"><a href="chapter4.html#learning-objectives-2"><i class="fa fa-check"></i><b>4.2</b> Learning Objectives</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="chapter5.html"><a href="chapter5.html"><i class="fa fa-check"></i><b>5</b> Effective data visualization</a><ul>
<li class="chapter" data-level="5.1" data-path="chapter5.html"><a href="chapter5.html#overview-3"><i class="fa fa-check"></i><b>5.1</b> Overview</a></li>
<li class="chapter" data-level="5.2" data-path="chapter5.html"><a href="chapter5.html#learning-objectives-3"><i class="fa fa-check"></i><b>5.2</b> Learning Objectives</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="chapter6.html"><a href="chapter6.html"><i class="fa fa-check"></i><b>6</b> Classification</a><ul>
<li class="chapter" data-level="6.1" data-path="chapter6.html"><a href="chapter6.html#learning-objectives-4"><i class="fa fa-check"></i><b>6.1</b> Learning objectives</a></li>
<li class="chapter" data-level="6.2" data-path="chapter6.html"><a href="chapter6.html#classification"><i class="fa fa-check"></i><b>6.2</b> Classification</a></li>
<li class="chapter" data-level="6.3" data-path="chapter6.html"><a href="chapter6.html#wisconsin-breast-cancer-example"><i class="fa fa-check"></i><b>6.3</b> Wisconsin Breast Cancer Example:</a><ul>
<li class="chapter" data-level="6.3.1" data-path="chapter6.html"><a href="chapter6.html#data-exploration"><i class="fa fa-check"></i><b>6.3.1</b> Data Exploration</a></li>
<li class="chapter" data-level="6.3.2" data-path="chapter6.html"><a href="chapter6.html#k-nearest-neighbour-classifier"><i class="fa fa-check"></i><b>6.3.2</b> K-Nearest Neighbour Classifier</a></li>
<li class="chapter" data-level="6.3.3" data-path="chapter6.html"><a href="chapter6.html#k-nearest-neighbours-in-r"><i class="fa fa-check"></i><b>6.3.3</b> K-Nearest Neighbours in R</a></li>
<li class="chapter" data-level="6.3.4" data-path="chapter6.html"><a href="chapter6.html#multiple-attributes"><i class="fa fa-check"></i><b>6.3.4</b> Multiple Attributes</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="chapter7.html"><a href="chapter7.html"><i class="fa fa-check"></i><b>7</b> Classification, continued</a><ul>
<li class="chapter" data-level="7.1" data-path="chapter7.html"><a href="chapter7.html#overview-4"><i class="fa fa-check"></i><b>7.1</b> Overview</a></li>
<li class="chapter" data-level="7.2" data-path="chapter7.html"><a href="chapter7.html#learning-objectives-5"><i class="fa fa-check"></i><b>7.2</b> Learning Objectives</a></li>
<li class="chapter" data-level="7.3" data-path="chapter7.html"><a href="chapter7.html#data-set"><i class="fa fa-check"></i><b>7.3</b> Data set</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="chapter8.html"><a href="chapter8.html"><i class="fa fa-check"></i><b>8</b> Clustering</a><ul>
<li class="chapter" data-level="8.1" data-path="chapter8.html"><a href="chapter8.html#learning-objectives-6"><i class="fa fa-check"></i><b>8.1</b> Learning Objectives</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="chapter9.html"><a href="chapter9.html"><i class="fa fa-check"></i><b>9</b> Regression</a><ul>
<li class="chapter" data-level="9.1" data-path="chapter9.html"><a href="chapter9.html#overview-5"><i class="fa fa-check"></i><b>9.1</b> Overview</a></li>
<li class="chapter" data-level="9.2" data-path="chapter9.html"><a href="chapter9.html#learning-objectives-7"><i class="fa fa-check"></i><b>9.2</b> Learning Objectives</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="chapter10.html"><a href="chapter10.html"><i class="fa fa-check"></i><b>10</b> Regression, continued</a><ul>
<li class="chapter" data-level="10.1" data-path="chapter10.html"><a href="chapter10.html#overview-6"><i class="fa fa-check"></i><b>10.1</b> Overview</a></li>
<li class="chapter" data-level="10.2" data-path="chapter10.html"><a href="chapter10.html#learning-objectives-8"><i class="fa fa-check"></i><b>10.2</b> Learning Objectives</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="chapter11.html"><a href="chapter11.html"><i class="fa fa-check"></i><b>11</b> Regression, continued some more…</a><ul>
<li class="chapter" data-level="11.1" data-path="chapter11.html"><a href="chapter11.html#overview-7"><i class="fa fa-check"></i><b>11.1</b> Overview</a></li>
<li class="chapter" data-level="11.2" data-path="chapter11.html"><a href="chapter11.html#learning-objectives-9"><i class="fa fa-check"></i><b>11.2</b> Learning Objectives</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Introduction to Data Science</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="chapter6" class="section level1">
<h1><span class="header-section-number">Chapter 6</span> Classification</h1>
<div id="learning-objectives-4" class="section level2">
<h2><span class="header-section-number">6.1</span> Learning objectives</h2>
<p>By the end of the chapter, students will be able to:</p>
<ul>
<li>Recognize situations where a simple classifier would be appropriate for making predictions.</li>
<li>Explain the k-nearest neighbour classification algorithm.</li>
<li>Interpret the output of a classifier.</li>
<li>Compute, by hand, the distance between points when there are two attributes.</li>
<li>Describe what a training data set is and how it is used in classification.</li>
<li>In a dataset with two attributes, perform k-nearest neighbour classification in R using caret::train(method = “knn”, …) to predict the class of a single new observation.</li>
</ul>
</div>
<div id="classification" class="section level2">
<h2><span class="header-section-number">6.2</span> Classification</h2>
<p>In many situations, we want to learn how to make predictions based on our experience from past examples. For instance, a doctor wants to diagnose a patient as either diseased or healthy based on some observed characteristics, an email provider would like to assign a given email as “spam” or “non-spam”, or an online store wants to predict if an order is fraudulent. These are all examples of classification tasks.</p>
<p><strong>Classification</strong> is the problem of predicting a qualitative or categorical response for an observation. It involves assigning an observation to a class (e.g. disease or healthy) on the basis of how similar they are to other observations that have already been classified. These already classified observations that we use as a basis to predict classes for new, unclassfied observations is called a <strong>training set</strong>. We call them a “training set” because we use these observations to train, or teach, our classifier so that we can make predictions on new data that we have not seen previously.</p>
<p>There are many possible classifiers that we could use to predict a qualitative response. These classification methods can perform binary classification, only two classes are involved (e.g. disease or healthy patient), but we can also have multiclass classification, which involves assigning an object to one of several classes (e.g., private, public, or not for-profit organization). Here we will focus on a simple, and widely used method of classification called <strong>K-nearest neighbors</strong>, but others include decision trees, support vector machines and logistic regression.</p>
</div>
<div id="wisconsin-breast-cancer-example" class="section level2">
<h2><span class="header-section-number">6.3</span> Wisconsin Breast Cancer Example:</h2>
<p>Let’s start by looking at some Breast Cancer <a href="http://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29">data</a>, which was obtained from the University of Wisconsin Hospitals, Madison from Dr. William H. Wolberg. Each row in the data set represents an observation whose diagnosis class is known (benign/non-cancerous or malignant/cancerous) and for each, we have several attributes (texture, perimeter etc.). We’d like to find which attributes are most useful for diagnosing benign or malignant tumours, and develop a way to classify future patients. Benign tumours are not normally dangerous, the cells stay in the same place and the tumour stops growing before it gets very large. In malignant tumours, the cells invade the surrounding tissue and spread into nearby organs where they can cause serious damage. (<a href="https://www.worldwidecancerresearch.org/who-we-are/cancer-basics/" class="uri">https://www.worldwidecancerresearch.org/who-we-are/cancer-basics/</a>)</p>
<!--http://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.names-->
<div id="data-exploration" class="section level3">
<h3><span class="header-section-number">6.3.1</span> Data Exploration</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">suppressMessages</span>({
<span class="kw">library</span>(tidyverse)
<span class="kw">library</span>(ggplot2)
<span class="kw">library</span>(forcats) <span class="co"># fct_recode()</span>
})</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">bcDat &lt;-<span class="st"> </span><span class="kw">read_csv</span>(<span class="st">&quot;data/clean-wdbc.data.csv&quot;</span>)</code></pre></div>
<pre><code>## Parsed with column specification:
## cols(
##   ID = col_integer(),
##   Class = col_character(),
##   Radius = col_double(),
##   Texture = col_double(),
##   Perimeter = col_double(),
##   Area = col_double(),
##   Smoothness = col_double(),
##   Compactness = col_double(),
##   Concavity = col_double(),
##   Concave_points = col_double(),
##   Symmetry = col_double(),
##   Fractal_dimension = col_double()
## )</code></pre>
<div id="attribute-description" class="section level4">
<h4><span class="header-section-number">6.3.1.1</span> Attribute description</h4>
<p>Breast tumours can be diagnosed by performing a biopsy, a process where tissue is removed from the body to discover the presence of a disease. Fine needle asipiration is a type of biopsy that uses a thin needle to examine a small amount of tissue from the tumour. Attributes in this dataset are computed from an image of a fine needle aspirate (FNA) of a breast mass. They describe characteristics of the cell nuclei present in the image.</p>
<div class="figure">
<img src="https://ai2-s2-public.s3.amazonaws.com/figures/2017-08-08/3721bb14b16e866115c906336e9d70db096c05b9/1-Figure1-1.png" title="A magnified image of a malignant breast Fine Needle Aspiration." alt="Source: https://www.semanticscholar.org/paper/Breast-Cancer-Diagnosis-and-Prognosis-Via-Linear-P-Mangasarian-Street/3721bb14b16e866115c906336e9d70db096c05b9/figure/0" />
<p class="caption">Source: <a href="https://www.semanticscholar.org/paper/Breast-Cancer-Diagnosis-and-Prognosis-Via-Linear-P-Mangasarian-Street/3721bb14b16e866115c906336e9d70db096c05b9/figure/0" class="uri">https://www.semanticscholar.org/paper/Breast-Cancer-Diagnosis-and-Prognosis-Via-Linear-P-Mangasarian-Street/3721bb14b16e866115c906336e9d70db096c05b9/figure/0</a></p>
</div>
<p>A magnified image of a malignant breast Fine Needle Aspiration</p>
<ol style="list-style-type: decimal">
<li>ID number</li>
<li>Class - diagnosis (M = malignant, B = benign)</li>
<li>radius (mean of distances from center to points on the perimeter)</li>
<li>texture (standard deviation of gray-scale values)</li>
<li>perimeter</li>
<li>area</li>
<li>smoothness (local variation in radius lengths)</li>
<li>compactness (perimeter^2 / area - 1.0)</li>
<li>concavity (severity of concave portions of the contour)</li>
<li>concave points (number of concave portions of the contour)</li>
<li>symmetry</li>
<li>fractal dimension (“coastline approximation” - 1)</li>
</ol>
<p>The “worst” or largest (mean of the three largest values) of these features were computed for each image. As part of the data preparation, the data have been scaled.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">glimpse</span>(bcDat)</code></pre></div>
<pre><code>## Observations: 569
## Variables: 12
## $ ID                &lt;int&gt; 842302, 842517, 84300903, 84348301, 84358402...
## $ Class             &lt;chr&gt; &quot;M&quot;, &quot;M&quot;, &quot;M&quot;, &quot;M&quot;, &quot;M&quot;, &quot;M&quot;, &quot;M&quot;, &quot;M&quot;, &quot;M&quot;,...
## $ Radius            &lt;dbl&gt; 1.8850310, 1.8043398, 1.5105411, -0.2812170,...
## $ Texture           &lt;dbl&gt; -1.35809849, -0.36887865, -0.02395331, 0.133...
## $ Perimeter         &lt;dbl&gt; 2.30157548, 1.53377643, 1.34629062, -0.24971...
## $ Area              &lt;dbl&gt; 1.999478159, 1.888827020, 1.455004298, -0.54...
## $ Smoothness        &lt;dbl&gt; 1.306536657, -0.375281748, 0.526943750, 3.39...
## $ Compactness       &lt;dbl&gt; 2.61436466, -0.43006581, 1.08198014, 3.88997...
## $ Concavity         &lt;dbl&gt; 2.10767182, -0.14661996, 0.85422232, 1.98783...
## $ Concave_points    &lt;dbl&gt; 2.29405760, 1.08612862, 1.95328166, 2.173873...
## $ Symmetry          &lt;dbl&gt; 2.7482041, -0.2436753, 1.1512420, 6.0407261,...
## $ Fractal_dimension &lt;dbl&gt; 1.93531174, 0.28094279, 0.20121416, 4.930671...</code></pre>
<p>We can see from the summary of the data above that “Class” is an character variable. We are going to be working with “Class” as a categorical variable so we will convert it to factor.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">bcDat &lt;-<span class="st"> </span>bcDat <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">Class =</span> <span class="kw">as.factor</span>(Class)) 

bcDat<span class="op">$</span>Class <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">levels</span>()</code></pre></div>
<pre><code>## [1] &quot;B&quot; &quot;M&quot;</code></pre>
<p>In our dataset, we have 357 (63%) benign and 212 (37%) malignant observations.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">bcDat <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">group_by</span>(Class) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">tally</span>()</code></pre></div>
<pre><code>## # A tibble: 2 x 2
##   Class     n
##   &lt;fct&gt; &lt;int&gt;
## 1 B       357
## 2 M       212</code></pre>
<p>Let’s draw a scatter plot to visualize the relationship between the perimeter and concavity variables.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">cbPalette &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;#999999&quot;</span>, <span class="st">&quot;#E69F00&quot;</span>, <span class="st">&quot;#56B4E9&quot;</span>, <span class="st">&quot;#009E73&quot;</span>, <span class="st">&quot;#F0E442&quot;</span>, <span class="st">&quot;#0072B2&quot;</span>, <span class="st">&quot;#D55E00&quot;</span>, <span class="st">&quot;#CC79A7&quot;</span>) <span class="co"># colour palette</span>

p &lt;-<span class="st"> </span>bcDat <span class="op">%&gt;%</span><span class="st">  </span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x=</span>Perimeter, <span class="dt">y=</span>Concavity, <span class="dt">color =</span> Class)) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="dt">name =</span> <span class="st">&quot;Perimeter&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="dt">name =</span> <span class="st">&quot;Concavity&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_color_manual</span>(<span class="dt">values=</span><span class="kw">c</span>(cbPalette[<span class="dv">3</span>], cbPalette[<span class="dv">2</span>]))
p</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<p>Suppose we have a new observation that is not in the data set with perimeter 1 and concavity 1, would you classify that observation as benign or malignant? What about a new observation with perimeter -1 and concavity -0.5? What about 0 and 1?</p>
<p>We can see that most of the benign observations are clustered in the lower-left corner and most of the malignant observations are above and to the right of that cluster, though not all the observations follow this pattern. We want to find a way to program a computer to automatically detect patterns.</p>
</div>
</div>
<div id="k-nearest-neighbour-classifier" class="section level3">
<h3><span class="header-section-number">6.3.2</span> K-Nearest Neighbour Classifier</h3>
<p>To classify a new observation as benign or malignant, we find some observations in the training set that are “nearest” to our new observation, and then use that diagnosis (benign or malignant) to make a prediction. Suppose we have a new observation, with perimeter of 2 and concavity of 4 (labelled in red on the scatterplot), whose “Class” is unknown.</p>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
<p>We see that the nearest point to this new observation is located at the coordinates (2.3, 3.2). The idea here is that if a point is close to one another in the scatterplot then the perimeter and concavity values are similar so we may expect that they would have the same diagnosis.</p>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
<p>Suppose we have another new observation with perimeter 0.38 and concavity of 1.8. Looking at the scatterplot below, how would you classify this red observation? The nearest neighbour to this new point is a <strong>benign</strong> observation at (0.2, 1.8). <img src="bookdown-demo_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
<p>We can look at a few points, say <span class="math inline">\(k = 3\)</span>, that are closest to the new red observation to predict its class rather than just looking at one. Among those 3 closest points, we look at their class and use the majority class as our prediction for the new observation. <!-- For our red observation at (0.38, 1.8), the nearest points are: (0.2, 1.8), (0.5, 1.7), and (0.4, 2). --></p>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
<p>We see that the diagnoses of 2 of the 3 nearest neighbours to our new observation are malignant so we take majority vote and classify our new red observation as malignant.</p>
<pre><code>## # A tibble: 3 x 4
##        ID Perimeter Concavity Class
##     &lt;int&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;fct&gt;
## 1 9113239     0.230      1.84 B    
## 2 8511133     0.531      1.72 M    
## 3  899667     0.361      1.99 M</code></pre>
<p>Here we chose the <span class="math inline">\(k=3\)</span> nearest observations, but there is nothing special about <span class="math inline">\(k=3\)</span>. We could have used <span class="math inline">\(k=4, 5\)</span> or more, though we may want to choose an odd number to avoid ties. We will discuss more about choosing <span class="math inline">\(k\)</span> in the next section.</p>
<div id="distance-between-points-when-there-are-two-attributes" class="section level4">
<h4><span class="header-section-number">6.3.2.1</span> Distance Between Points When There are Two Attributes</h4>
<p>How do we decide which points are “nearest” to our new observation? We can compute the distance between any pair of points using the following formula:</p>
<p><span class="math display">\[Distance = \sqrt{(x_a -x_b)^2 + (y_a - y_b)^2}\]</span></p>
<p>Suppose we want to classify a new observation with perimeter of -1 and concavity of 4.2. Let’s calculate the distances between our new point and each of the observations in the training set to find the <span class="math inline">\(k=5\)</span> observations in the training data that are nearest to our new point.</p>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-15-1.png" width="672" /><img src="bookdown-demo_files/figure-html/unnamed-chunk-15-2.png" width="672" /></p>
<table>
<thead>
<tr class="header">
<th>ID</th>
<th>Perimeter</th>
<th>Concavity</th>
<th>Distance</th>
<th>Class</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>859471</td>
<td>-1.24</td>
<td>4.7</td>
<td><span class="math inline">\(\sqrt{-1 - (-1.24))^2 + (4.2 - 4.7)^2}=\)</span> 0.55</td>
<td>B</td>
</tr>
<tr class="even">
<td>84501001</td>
<td>-0.29</td>
<td>3.99</td>
<td><span class="math inline">\(\sqrt{(-1 - (-0.29))^2 + (4.2 - 3.99)^2} =\)</span> 0.74</td>
<td>M</td>
</tr>
<tr class="odd">
<td>8710441</td>
<td>-1.08</td>
<td>2.63</td>
<td><span class="math inline">\(\sqrt{(-1 - (-1.08))^2 + (4.2 - 2.63)^2} =\)</span> 1.57</td>
<td>B</td>
</tr>
<tr class="even">
<td>9013838</td>
<td>-0.46</td>
<td>2.72</td>
<td><span class="math inline">\(\sqrt{(-1 - (-0.46))^2 + (4.2 - 2.72)^2} =\)</span> 1.57</td>
<td>M</td>
</tr>
<tr class="odd">
<td>925622</td>
<td>0.64</td>
<td>4.3</td>
<td><span class="math inline">\(\sqrt{(-1 - 0.64)^2 + (4.2 - 4.3)^2} =\)</span> 1.64</td>
<td>M</td>
</tr>
</tbody>
</table>
<hr />
<p>From the table, we see that 3 of the 5 nearest neighbours to our new observation are malignant so classify our new observation as malignant.</p>
<div id="summary" class="section level5">
<h5><span class="header-section-number">6.3.2.1.1</span> Summary:</h5>
<p>In order to classify a new observation using a k-nearest neighbor classifier, we have to do the follow steps:</p>
<ul>
<li><strong>Step 1</strong>: Compute the distance between the new observation and each observation in our training set.</li>
<li><strong>Step 2</strong>: Sort the data table in ascending order according to the distances.</li>
<li><strong>Step 3</strong>: Choose the top <span class="math inline">\(k\)</span> rows of the sorted table.</li>
<li><strong>Step 4</strong>: Classify the new observation based on majority vote.</li>
</ul>
</div>
</div>
</div>
<div id="k-nearest-neighbours-in-r" class="section level3">
<h3><span class="header-section-number">6.3.3</span> K-Nearest Neighbours in R</h3>
<p>We will implement the k-nearest neighbour algorithm in R. Here we will make use of the <code>caret</code> (Classification And REgression Training) package in R, which contains a set of tools to help the process of making predictive models. We can use the function <code>names(getModelInfo())</code> to see a full list of the algorithms <code>caret</code> has to offer.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(caret)</code></pre></div>
<pre><code>## Loading required package: lattice</code></pre>
<pre><code>## 
## Attaching package: &#39;caret&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:purrr&#39;:
## 
##     lift</code></pre>
<p>Let’s suppose we have a new observation with perimeter 0 and concavity 0.5, but its diagnosis is unknown. Suppose we want to use its perimeter and concavity attributes to predict the class of this observation. Let’s pick out our 2 desired attributes and store it as a new dataset.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">trainingDat &lt;-<span class="st"> </span>bcDat <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">select</span>(<span class="st">&quot;Perimeter&quot;</span>, <span class="st">&quot;Concavity&quot;</span>)
<span class="kw">glimpse</span>(trainingDat)</code></pre></div>
<pre><code>## Observations: 569
## Variables: 2
## $ Perimeter &lt;dbl&gt; 2.30157548, 1.53377643, 1.34629062, -0.24971958, 1.3...
## $ Concavity &lt;dbl&gt; 2.10767182, -0.14661996, 0.85422232, 1.98783917, 0.6...</code></pre>
<p>We will store the class labels in a vector.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">labels &lt;-<span class="st"> </span>bcDat<span class="op">$</span>Class
<span class="kw">glimpse</span>(labels)</code></pre></div>
<pre><code>##  Factor w/ 2 levels &quot;B&quot;,&quot;M&quot;: 2 2 2 2 2 2 2 2 2 2 ...</code></pre>
<p>We will use the function <code>train()</code>, where <code>x</code> is an object where observations are in rows and the attributes are in columns (e.g. simple matrix, dataframe) and <code>y</code> is a numeric or factor vector containing the outcome for each row. The argument <code>tuneGrid</code> should be a dataframe with possible “tuning values”. For now, just know that this is where we will specify our <span class="math inline">\(k\)</span> and we will use <span class="math inline">\(k =7\)</span> (we will discuss how to choose <span class="math inline">\(k\)</span> in a later section). We will use “knn” as our <code>method</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">k &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">k =</span> <span class="dv">7</span>)
model_knn &lt;-<span class="st"> </span><span class="kw">train</span>(<span class="dt">x =</span> <span class="kw">data.frame</span>(trainingDat), <span class="dt">y =</span> labels, <span class="dt">method=</span><span class="st">&#39;knn&#39;</span>, <span class="dt">tuneGrid =</span> k)</code></pre></div>
<p>Now we can predict the label of the new observation.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">new_obs &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">Perimeter =</span> <span class="dv">0</span>, <span class="dt">Concavity =</span> <span class="fl">0.5</span>)
<span class="kw">predict</span>(<span class="dt">object=</span>model_knn, new_obs)</code></pre></div>
<pre><code>## [1] M
## Levels: B M</code></pre>
<p>Our model classifies this new observation as malignant. How do we know how well our model did? In later sections, we will discuss ways to evaluate our model.</p>
</div>
<div id="multiple-attributes" class="section level3">
<h3><span class="header-section-number">6.3.4</span> Multiple Attributes</h3>
<p>So far we have seen how to build a classifier based on only two attributes, but we can use k-nearest neighbours classifier in higher dimensional space. Let’s make a scatterplot with 3 variables instead of 2:</p>
<pre><code>## 
## Attaching package: &#39;plotly&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:ggplot2&#39;:
## 
##     last_plot</code></pre>
<pre><code>## The following object is masked from &#39;package:stats&#39;:
## 
##     filter</code></pre>
<pre><code>## The following object is masked from &#39;package:graphics&#39;:
## 
##     layout</code></pre>
<p><div id="e9cedb93726" style="width:672px;height:480px;" class="plotly html-widget"></div>
<script type="application/json" data-for="e9cedb93726">{"x":{"visdat":{"e9ce74ef58f4":["function () ","plotlyVisDat"]},"cur_data":"e9ce74ef58f4","attrs":{"e9ce74ef58f4":{"x":{},"y":{},"z":{},"color":{},"colors":["#56B4E9","#E69F00"],"alpha":1,"sizes":[10,100],"type":"scatter3d","mode":"markers"}},"layout":{"margin":{"b":40,"l":60,"t":25,"r":10},"scene":{"xaxis":{"title":"Perimeter"},"yaxis":{"title":"Concavity"},"zaxis":{"title":"Symmetry"}},"xaxis":{"domain":[0,1]},"yaxis":{"domain":[0,1]},"hovermode":"closest","showlegend":true},"source":"A","config":{"modeBarButtonsToAdd":[{"name":"Collaborate","icon":{"width":1000,"ascent":500,"descent":-50,"path":"M487 375c7-10 9-23 5-36l-79-259c-3-12-11-23-22-31-11-8-22-12-35-12l-263 0c-15 0-29 5-43 15-13 10-23 23-28 37-5 13-5 25-1 37 0 0 0 3 1 7 1 5 1 8 1 11 0 2 0 4-1 6 0 3-1 5-1 6 1 2 2 4 3 6 1 2 2 4 4 6 2 3 4 5 5 7 5 7 9 16 13 26 4 10 7 19 9 26 0 2 0 5 0 9-1 4-1 6 0 8 0 2 2 5 4 8 3 3 5 5 5 7 4 6 8 15 12 26 4 11 7 19 7 26 1 1 0 4 0 9-1 4-1 7 0 8 1 2 3 5 6 8 4 4 6 6 6 7 4 5 8 13 13 24 4 11 7 20 7 28 1 1 0 4 0 7-1 3-1 6-1 7 0 2 1 4 3 6 1 1 3 4 5 6 2 3 3 5 5 6 1 2 3 5 4 9 2 3 3 7 5 10 1 3 2 6 4 10 2 4 4 7 6 9 2 3 4 5 7 7 3 2 7 3 11 3 3 0 8 0 13-1l0-1c7 2 12 2 14 2l218 0c14 0 25-5 32-16 8-10 10-23 6-37l-79-259c-7-22-13-37-20-43-7-7-19-10-37-10l-248 0c-5 0-9-2-11-5-2-3-2-7 0-12 4-13 18-20 41-20l264 0c5 0 10 2 16 5 5 3 8 6 10 11l85 282c2 5 2 10 2 17 7-3 13-7 17-13z m-304 0c-1-3-1-5 0-7 1-1 3-2 6-2l174 0c2 0 4 1 7 2 2 2 4 4 5 7l6 18c0 3 0 5-1 7-1 1-3 2-6 2l-173 0c-3 0-5-1-8-2-2-2-4-4-4-7z m-24-73c-1-3-1-5 0-7 2-2 3-2 6-2l174 0c2 0 5 0 7 2 3 2 4 4 5 7l6 18c1 2 0 5-1 6-1 2-3 3-5 3l-174 0c-3 0-5-1-7-3-3-1-4-4-5-6z"},"click":"function(gd) { \n        // is this being viewed in RStudio?\n        if (location.search == '?viewer_pane=1') {\n          alert('To learn about plotly for collaboration, visit:\\n https://cpsievert.github.io/plotly_book/plot-ly-for-collaboration.html');\n        } else {\n          window.open('https://cpsievert.github.io/plotly_book/plot-ly-for-collaboration.html', '_blank');\n        }\n      }"}],"cloud":false},"data":[{"x":[-0.22501906532072,-0.332451412882306,-1.25381027174843,-0.678556178018386,-1.4880187413633,-0.517258858410686,-0.245850822465626,-0.722600464553329,-0.332749009412948,-0.702066303939065,-0.757419258638386,-0.506545383307591,-1.40945325727394,-1.11304711275499,-1.34517240665537,-1.24012083133892,-1.19726693092654,-0.870803536812803,-1.24279920011469,-0.642546997810762,-1.3302925801233,-0.522317999431592,-0.473214571875742,-0.457739552282383,-0.676473002303895,-0.31548841063574,-0.579754129845403,-0.470238606569327,0.0636495694015471,-0.129788175515436,-0.0821727306127943,-0.287811933286079,-0.747598573127216,-1.14429474847235,-0.723195657614613,-1.69187236485274,-0.674985019650687,-1.0428143315236,-0.983295025395294,-0.647308542301027,-0.645820559647819,-0.692543214958537,-1.05888454417824,-0.543447353107139,-0.00777359795241612,-1.03091047029794,-1.27315404624013,-0.586896446580799,-1.30708005073326,-0.699983128224575,-0.132764140821852,-0.454465990445327,-0.20716327348223,-0.0405092163229823,-0.472619378814459,0.209471869415888,-0.627964767809328,-0.813367406398991,-0.914550226817105,-1.21214675745862,-0.732123553533858,-0.300310987573023,-0.877053063956274,-0.624988802502913,-0.00479763264600116,0.0398418469502257,-0.29971579451174,-0.489284784530384,-1.4636158258507,-1.0779307221393,-0.922882929675067,-0.285431161040947,-0.614870520461102,0.388029787800796,-0.689864846182763,-0.868720361098312,-0.546125721882913,-0.592253184132347,-0.147643967353927,-0.999960431111219,-0.0791967653063793,-0.603859448827366,-1.04906385866707,-1.01364987152073,-1.45528312299273,-1.01751862641907,-0.567850268619743,-0.611894555154687,-0.837472725380953,-0.948476231310237,-0.679746564140951,-0.824080881502085,-0.613382537807894,-0.542256966984573,-1.33951807257319,-0.489582381061025,-0.449704445955062,-0.333641799004873,-1.19577894827333,-0.231566188994833,0.191616077577397,-0.655938841689631,-0.626774381686762,-0.948178634779596,-0.224721468790079,-0.183355551030909,-1.05114703438156,-0.25061236695589,0.0934092224656983,-1.00561476519341,0.206495904109473,-0.493748732490006,-0.816640968236048,-0.857709289464576,-1.2356568833793,-0.267575369202457,-0.141692036741097,-0.391375525949326,-0.696709566387518,-0.598205114745177,-0.275610475529777,-0.999365238049936,-0.564874303313328,-0.0672929040807186,-0.871398729874086,-0.785095735988047,-0.718434113124348,-0.86247083395484,-0.285728757571589,-0.535412246779818,-0.915145419878388,-0.381554840438156,-0.862768430485482,-1.16572169867854,-0.827354443339142,-0.889552118243218,-0.2485291912414,-0.264599403896041,-0.671413861282989,-0.450597235546987,-0.645820559647819,-0.448216463301855,-0.591062798009781,-0.862768430485482,-0.832413584360047,-0.165499759192418,0.0547216734823014,-0.549101687189328,-0.681829739855442,-0.557136793516648,-0.389589946765477,-1.03686240091077,-0.0434851816293977,-1.1059047960196,-0.569338251272951,-1.08626342499726,-0.731230763941933,-0.76991831292533,-0.454168393914685,-1.37969360420979,-0.350604801251439,-0.395839473908949,-0.783905349865481,-0.105980453064115,-0.452978007792119,-0.774679857415594,-1.50617212973243,-0.677960984957102,-0.763668785781858,-1.14994908255454,-0.758907241291594,-1.06334849213786,-0.430360671463364,-0.48065448514178,-0.552375249026384,-0.263706614304117,-0.729742781288726,-0.239601295322155,-0.903241558652728,-0.749384152311066,-0.676473002303895,-0.591657991071064,-1.04995664825899,0.12316887552985,-1.07168119499582,-0.818426547419896,-0.687484073937631,-1.08239467009892,-0.616656099644951,0.206495904109473,-0.82110491619567,-0.719326902716273,-0.703851883122914,-0.822592898848877,-0.542852160045856,-0.388101964112269,-0.313107638390608,-1.24964392031945,-0.936572370084577,-0.608323396786989,-0.426194320034383,-0.578563743722837,0.295774863301927,-0.401791404521779,-0.399113035746005,-0.0821727306127943,-0.241089277975362,0.173760285738906,-0.915145419878388,-0.302096566756872,-0.276800861652344,-0.664569141078234,-0.819319337011821,-0.592253184132347,-0.358044714517476,-0.317571586350231,-0.583622884743743,-0.226209451443286,-0.819319337011821,-1.0127570819288,-1.28714108318028,-0.56338632066012,-0.322630727371136,-0.295549443082759,-0.492260749836799,-0.78777410476382,-0.632726312299593,-0.583920481274384,-0.325904289208193,-0.522913192492874,-0.688972056590838,-0.729147588227443,0.25708731431853,-0.465179465548421,-0.543447353107139,-0.660402789649253,-0.813367406398991,-1.20976598521349,0.087457291852868,-0.65980759658797,-1.14667552071748,-0.569635847803592,-0.833306373951972,-0.619929661482007,0.203519938803058,-0.753848100270688,-0.174427655111663,-1.05561098234118,-1.11126153357114,-0.769323119864047,-0.701471110877782,-0.979426270496955,-0.547316108005478,-0.525293964738006,-0.147643967353927,-0.36072308329325,-0.180379585724493,-0.189307481643739,-0.31935716553408,-0.509521348614006,-0.278586440836192,-1.12822453581771,-0.677960984957102,-0.0405092163229823,0.0249620204181501,-0.706827848429329,-0.660402789649253,-0.123836244902606,-0.465477062079062,-0.314595621043816,-0.631535926177026,-0.475297747590232,-0.482142467794987,-1.16750727786239,-0.204187308175814,-0.731528360472575,-0.361913469415816,0.230303626560794,-0.189307481643739,-1.0758475464248,-0.569040654742309,-1.08269226662956,-0.595824342500045,0.14102466736834,-0.660105193118612,-0.788071701294462,-0.417861617176421,0.144000632674755,-0.180379585724493,-0.750574538433631,-0.548506494128045,-0.0851486959192092,-0.36667501390608,-0.341676905332193,0.155904493900416,-0.280967213081325,-0.0375332510165674,-0.615763310053027,-0.432146250647213,0.590395428637024,-0.71486295475665,-0.356259135333627,-0.100028522451285,-0.356259135333627,-0.429765478402081,0.0725774653207924,-0.612787344746611,-1.13715243173696,-1.12465337745001,-0.658617210465404,-0.927942070695973,0.0755534306272073,-0.774084664354311,-0.165499759192418,0.0368658816438108,-0.836579935789029,-0.236625330015739,-0.405660159420119,-1.17316161194458,-0.919014174776728,-0.233054171648041,-0.980319060088879,-1.30827043685583,-0.159547828579587,-0.596419535561328,-0.379174068193024,-0.605347431480573,-0.557731986577932,-0.602966659235441,-0.168475724498833,-0.91752619212352,-0.629155153931894,-1.49069711013907,-1.570452980351,-0.847591007422765,0.185664146964567,0.00413026327324455,-0.439883760443892,-0.24079168144472,-0.288109529816721,-1.07554994989416,-1.07674033601673,-1.13566444908375,-0.69522158373431,-0.987461376824276,-0.876755467425633,-0.570231040864875,-1.32136468420405,-0.548208897597403,-1.1216774121436,-1.17197122582201,-1.21303954705054,-0.0405092163229823,-0.743432221698235,-0.210139238788645,-0.954428161923068,-1.43147540054141],"y":[-0.159082553609287,-0.398747849778323,-0.879660233071109,-1.07302219402029,-0.974903221768684,0.15727563733384,-0.210850257581799,-1.03994838314896,-0.801385547342302,-0.86355472516855,-0.869642223691244,-1.29583901986864,-0.74482453744641,-1.20076379687838,-0.873237203133779,-0.635057831800992,-0.853536715788685,-0.612529293961102,4.69653634677537,-0.806658183858021,-0.617322599884483,-0.488382670545542,-0.895382276499798,-0.474961413960076,-0.463457479743962,1.02390534828107,-0.21804021646687,-0.137992007546412,-0.0565058068489398,-0.864225787997823,-0.657586369640881,-0.642727121278401,-1.06597603431292,-1.20646783092721,-0.383409270823504,-1.30468266929728,-0.755849141070186,-0.0373325831554169,-0.92184132519686,0.0724341224900012,-0.376219311938433,0.190828778797505,-0.681552899257785,-0.242486076676112,1.94661673853186,-0.683949552219475,-0.127446734514974,-0.584248789013156,-0.564596234727295,-0.297129764202652,-0.077596352911815,0.280942930157062,-0.915705893614932,-0.365194708314658,-0.829426386994079,-0.485506686991514,-0.803302869711655,-0.634099170616315,-0.889150978799403,-1.30468266929728,-0.935214648723092,-0.302881731310708,-0.837095676471489,-0.853153251314814,-0.106356188452099,0.182680158727758,-0.555009622880534,-0.915849692792634,1.27459524807388,2.63349747735232,-0.963591019789506,0.137623083047979,-0.373343328384405,-0.402582494517027,-0.890732769754119,-1.2158147774778,-0.36711203068401,-0.495572629430613,-0.933201460235272,-0.802823539119316,-0.986023691510927,-0.709354073613393,-1.11592228203454,-1.30468266929728,-1.30468266929728,0.366263775593239,-1.26644646794647,-1.17248329193044,-0.514745853124136,-1.27151299230748,-0.575620838351071,-0.882727948862073,-0.622595236400202,-1.05610182411075,-1.30468266929728,-0.45914350441292,-0.644644443647753,-0.0243906571622891,-1.00687457227763,0.210960663675704,0.11509454520809,-0.599587367967974,0.0403189728033505,-0.38197127904649,-0.46154015737461,-0.0694477328420679,-0.989666604012697,-0.448598231381482,-0.522415142601545,-1.17818732597926,0.326000005836841,0.569979277336919,-0.782691654241118,-1.19357383799331,-0.961434032123984,-1.00601177721142,0.163986265626573,-0.569868871243014,-1.00543658050062,2.25961961532862,-0.653272394309838,-0.738593239746015,-0.20318096810439,2.399104817699,-0.765435752916947,-0.439970280719397,-0.91618522420727,-0.386285254377533,-0.60821531863006,-0.349856129359839,-0.0900589483126048,-1.11937346229938,-0.693536164066236,-1.11088931081499,-0.961817496597855,-1.28093183844693,-0.796592241418922,-0.606777326853045,-0.981853515357586,0.298198831481233,-1.27794081555074,-0.171065818417739,-0.736196586784325,-0.563637573542619,-0.943794666325943,-0.240568754306759,-0.439970280719397,-0.23050281186766,-0.673883609780375,-1.05384897032676,-1.12579649223671,-1.16644372646698,-0.554530292288196,-1.10537700900311,-0.39203722148559,-0.90094251137092,-0.717023363090802,-0.957695253503747,-1.25099764295541,-1.23412520610511,-1.23858298061386,-1.21725276925481,-0.925292505461694,-1.07719237017363,-0.456746851451229,-0.905687884235067,-1.30468266929728,-1.21178840050216,-1.10739019749093,0.904552030788892,-1.19745641579125,-0.394913205039618,-0.446201578419792,-0.745303868038748,-0.815765465112445,-1.05030192394346,-1.2676208278977,0.343735237753349,-1.24069203522014,-1.27823320721206,-1.13121292793013,-0.609653310407074,-0.798988894380612,0.49520370493218,0.776091432042289,-0.202701637512052,-0.783650315425794,-0.96138609906475,-1.08869630438974,-0.273642565178086,-0.83383622844359,-1.15503565836933,-1.1586785708711,-0.729006627899254,-0.160041214793963,-0.0713650552114202,-1.05135645124661,-0.852146657070904,-0.756328471662524,-1.28751784078565,-0.723733991383535,-0.703122775912998,-0.507555894239065,-0.650875741348148,-0.148057949985512,-0.651834402532824,-0.659503692010233,-0.291377797094595,1.58568080250129,-0.924381777336251,-0.0732823775807723,-0.227626828313631,-0.560282259396253,0.0911280155911861,0.232051209738579,0.0690788083436348,0.16973823273463,-0.781732993056441,0.143375050156036,-0.891739363998029,-1.30468266929728,-0.536315729779349,-0.899168988179269,0.343255907161011,-0.393475213262604,-0.308154367826427,-0.610132640999412,-0.578976152497437,-0.535836399187011,-0.437094297165368,-1.06880408480771,-0.627867872915921,-0.197429000996333,-0.423673040579902,-0.644644443647753,-0.43661496657303,-0.793236927272555,-0.40929312280976,0.187952795243476,-0.746741859815762,-1.01032575254247,-0.854830908387997,-1.13298645112178,-0.077596352911815,0.238282507438974,-0.201263645735037,0.449667298660063,-1.20474224079479,-1.24548534114352,0.104069941584314,-0.381012617861814,-1.08514925800644,-1.1384028868152,-0.152851255908892,-0.71989934664483,-0.963063756137934,-0.769270397655652,-1.07685683875899,-1.00462171849364,0.986038231486365,-1.13610209997198,-1.11362149519132,-0.533439746225321,-0.317261649080851,0.506707639148294,0.237803176846636,-0.43661496657303,-0.646561766017105,-0.400185841555337,-0.969007455482926,0.0964006521069048,-0.638413145947358,-1.09080535899603,-0.960043973406204,-0.599108037375636,-0.413127767548465,-0.405458478071056,1.83780869407112,0.854222318593395,-0.997479692667807,0.222464597891817,-0.69257750288156,-1.03990045008973,0.205688027159985,-1.30468266929728,0.308264773920332,0.361470469669858,-0.100604221344043,-0.641289129501387,-0.0603404515876445,-0.528167109709602,-0.502762588315684,-0.418879734656522,-0.469688777444357,0.61455702242436,1.04211991078992,-0.136554015769398,-0.590480086713551,-0.71510604072145,-0.802344208526978,-1.22444272813988,-0.93569397931543,-0.489820662322556,0.412279512457694,-0.332600228035669,-0.415045089917817,-0.399227180370661,-0.298567755979666,0.0916073461835241,0.389750974617804,-0.70264344532066,-0.371426006015053,-0.0152833759078657,-0.776939687133061,-0.110190833190804,-0.52624978734025,-0.70743675124404,-0.622595236400202,-0.825543809196141,-1.18326823025804,-0.377177973123109,-0.900415247719348,-0.4639368103363,-0.0325392772320362,-0.446201578419792,-0.557406275842224,-0.527208448524926,-0.649917080163472,0.017311104371123,-0.726609974937563,-0.287063821763552,-0.636016492985668,-1.30468266929728,0.321686030505798,-0.443325594865763,0.63181292374853,-0.532481085040645,-0.795633580234245,-0.644644443647753,-0.80186487793464,-1.09454413761627,-0.450036223158496,-0.85650856546118,-1.00778530040308,-1.30468266929728,-0.555009622880534,-0.889917907747144,-0.921553726841457,-0.135595354584722,-0.346021484621135,-1.2565099447673,-1.30468266929728,0.450625959844739,0.435287380889921,-0.669090303856995,-1.30468266929728,-1.30468266929728],"z":[0.123238094688002,0.457824280674147,-0.728582774948222,-1.47695670785443,0.330131968148034,-0.248524334185492,-0.0480958942710862,-0.756060867517132,-0.896684047134497,-0.187102715502045,0.65502000381574,-0.746362717198693,0.516013182584781,1.06072595880377,0.11515630275597,0.616227402541983,-0.036781385566241,-0.809400694268546,2.14530243608253,-0.836878786837457,-1.04538901868389,-0.45703456603193,-0.308329594482532,-0.196800865820485,-0.224278958389395,1.01223520721158,0.773014166023413,0.11515630275597,0.404484453922732,-0.612204971126954,-1.41230237239817,-0.360053062847541,-1.08903069511687,-1.56262370233397,-0.20811537452533,0.05050196729971,-0.334191328665037,-0.450569132486304,-0.120832021659379,-0.153159189387509,0.132936245006441,-0.11598294650016,-0.594425028876482,-1.09064705350328,-0.812633411041359,-0.836878786837457,0.0408038169812712,-0.7479790755851,-2.01843676730061,0.186276071757855,-0.0190014433157698,-1.37835884628363,-0.86758959617918,-0.502292600851312,0.918486420799998,-0.287316935459248,-1.92145526411622,-0.363285779620353,-1.29107549341768,0.330131968148034,-0.511990751169751,1.04779509171252,-0.971036532909196,-0.280851501913622,-0.0788067036128098,-0.339040403824256,-0.890218613588871,0.477220581311025,0.680881737998243,0.334981043307253,-0.0674921949079647,1.53270260763447,0.343062835239286,-0.604123179194922,-0.625135838218206,-0.263071559663151,0.431962546491643,-1.0227600012742,-0.411776531212548,-1.31047179405456,-0.80293526072292,-0.119215663272972,-1.61434717069898,-0.308329594482532,-0.499059884078499,-0.463499999577556,-0.979118324841228,-1.80669381868135,-1.76143578386197,0.0521183256861163,-0.531387051806629,0.483686014856651,-0.676859306583214,-1.16661589766438,-1.60303266199414,0.199206938849107,-0.376216646711606,0.183043354985042,0.14263439532488,1.98366659744188,-0.938709365181066,-0.591192312103669,0.802108616978731,-0.052944969430306,-0.841727861996676,0.265477632691774,0.249314048827709,-0.638066705309458,0.260628557532555,-0.461883641191149,0.0860618518006526,-0.120832021659379,-0.0836557787720297,0.0165584411851737,-0.232360750321427,-1.09064705350328,-1.63374347133586,-0.599274104035702,0.000394857321108762,0.658252720588552,-0.384298438643638,-0.0286995936342086,-0.216197166457362,-0.423091039917393,0.821504917615608,-0.382682080257231,-0.259838842890337,0.0634328343909615,-0.735048208493847,1.13669480296488,-0.478047225055214,-0.71565190785697,-0.271153351595183,-0.0965866458632811,-1.10034520382172,-0.230744391935021,-0.914463989384968,0.0876782101870589,0.323666534602407,-1.45756040721755,-0.639683063695864,-0.704337399152124,-0.956489307431538,0.0876782101870589,0.591982026745886,-1.01629456772858,0.0989927188919049,0.77463052440982,0.323666534602407,-0.859507804247148,-0.125681096818598,-1.22480479957502,-0.427940115076613,-1.08903069511687,-0.348738554142695,-1.11165971252656,-1.11974150445859,0.554805783858537,-0.403694739280516,0.145867112097693,-1.02437635966061,-1.28299370148565,0.947580871755315,-0.599274104035702,-0.544317918897881,0.790794108273886,0.389937228445074,-1.59010179490288,-0.982351041614041,0.378622719740229,-1.61596352908539,-0.473198149895995,-0.838495145223863,-0.387531155416451,-0.343889478983476,-1.2943082101905,-1.17954676475563,1.12376393587362,0.632390986406048,-0.138611963909851,-0.560481502761946,-0.757677225903538,-0.0109196513837373,0.246081332054896,0.131319886620035,0.646938211883707,-0.219429883230175,-0.754444509130725,-0.0335486687934284,0.33659740169366,-0.0804230619992161,0.360842777489757,-0.274386068367996,-0.524921618261003,-1.26036468407596,0.343062835239286,-0.870822312951993,-0.754444509130725,-0.722117341402595,-1.07933254479843,-0.426323756690207,-0.253373409344712,-0.819098844586985,-0.258222484503931,0.512780465811967,-0.668777514651181,0.68249809638465,0.407717170695546,-0.490978092146467,-0.334191328665037,0.785945033114666,0.71482526411278,0.486918731629464,-1.1472195970275,-0.132146530364225,-0.266304276435963,-0.361669421233947,-0.579877803398824,-1.20217578216532,0.0585837592317425,-0.736664566880254,0.23961589850927,-0.610588612740547,-0.379449363484418,-1.47534034946802,-0.502292600851312,-0.196800865820485,-0.712419191084157,0.495000523561496,0.640472778338081,-0.974269249682009,-1.05023809384311,-0.198417224206891,-0.667161156264775,0.895857403390307,0.116772661142376,0.157181620802539,-0.848193295542302,0.423880754559611,0.281641216555839,-0.0464795358846799,-0.20326629936611,0.121621736301595,0.216986881099579,-0.119215663272972,-0.183869998729232,-0.253373409344712,0.477220581311025,-0.891834971975278,0.192741505303481,0.103841794051124,-0.836878786837457,-1.18924491507407,-0.557248785989133,-0.607355895967734,0.666334512520585,-0.284084218686435,-0.626752196604612,-1.23611930827986,-0.583110520171637,-1.68385058131446,-0.326109536733004,-0.487745375373653,1.13022936941925,-0.694639248833685,-0.962954740977163,-0.733431850107441,-0.476430866668808,0.596831101905106,-1.13913780509547,-0.0270832352478022,-0.73828092526666,-0.961338382590757,-0.93709300679466,-0.898300405520904,0.499849598720716,-1.07609982802562,-0.0901212123176558,-0.545934277284288,0.252546765600522,-0.389147513802857,0.441660696810082,-0.80293526072292,-0.343889478983476,-0.794853468790888,-0.516839826328971,0.17011248789379,-0.592808670490076,-0.358436704461133,0.0650491927773678,-0.799702543950107,-0.880520463270432,0.527327691289626,-0.618670404672579,-0.555632427602727,0.533793124835252,-0.720500983016189,-0.156391906160322,0.322050176216001,-1.80669381868135,-1.00336370063733,-0.345505837369882,-0.859507804247148,0.532176766448846,0.216986881099579,-1.16984861443719,0.410949887468358,0.221835956258799,-0.085272137158436,-0.309945952868939,-0.195184507434077,-0.971036532909196,-0.479663583441621,-0.916080347771375,-0.444103698940678,0.257395840759741,-0.515223467942564,0.275175783010213,1.26115439871818,-0.555632427602727,-0.0836557787720297,-0.644532138855084,0.132936245006441,0.997687981733917,0.338213760080066,-1.19732670700611,-0.193568149047671,-0.68332474012884,0.49338416517509,-0.153159189387509,-0.988816475159668,-0.158008264546728,0.254163123986929,-0.179020923570012,-0.924162139703408,0.462673355833366,-0.288933293845655,-0.691406532060872,-1.05347081061593,-0.418241964758174,-0.355203987688321,-0.339040403824256,-0.563714219534759,0.255779482373335,-0.71565190785697,0.43357890487805,-0.798086185563701,-0.752828150744319,-0.854658729087928,-1.09064705350328,-1.03245815159264,-0.688173815288059,-1.03892358513827,-1.27491190955362,-1.05185445222952,-2.15744358853156,-0.0480958942710862],"type":"scatter3d","mode":"markers","name":"B","marker":{"fillcolor":"rgba(86,180,233,0.5)","color":"rgba(86,180,233,1)","line":{"color":"transparent"}},"frame":null},{"x":[2.30157547982572,1.53377643077062,1.34629061646647,-0.249719577363966,1.33736272054722,-0.11490834898336,1.36712237361137,0.0993611530785282,-0.031581320403737,-0.28602635410223,0.492188573525325,0.870136167440046,1.32248289401514,0.14102466736834,0.0457937775630561,0.50111646944457,0.480284712299665,0.879064063359292,2.36704671656685,0.530876122508722,2.40275830024384,2.07540211653817,1.34331465116005,0.450525059235513,0.971318987858161,1.25105972666118,0.822520722537404,1.58436784097968,0.36124610004306,0.858232306214385,1.61115152873741,0.757049485796271,0.780857208247592,0.266015210237776,-0.348819222067589,0.00115429796682918,-0.141692036741097,-0.596419535561328,2.08730597776383,0.173760285738906,-0.052413077548643,1.28974727564458,-0.132764140821852,0.828472653150234,0.310654689834002,1.87006051039553,0.2511353837057,0.352318204123814,0.13507273675551,0.218399765335133,1.74506996752609,1.31950692870873,0.090433257159283,0.640986838846082,1.2748674491125,1.87601244100836,3.10806207786422,1.01298250214797,1.33736272054722,0.0338899163373958,1.35819447769213,0.00710622857965951,0.48326067760608,1.45342536749741,0.066625534707962,0.0398418469502257,-0.0256293897909067,2.96223977784988,0.590395428637024,0.685626318442309,0.652890700071742,1.13499707971099,2.19146476348836,0.176736251045322,1.21832410829062,1.23320393482269,0.524924191895892,0.667770526603817,1.14094901032382,-0.452978007792119,0.420765406171362,0.646938769458912,-0.456251569629175,0.763001416409102,1.17070866338797,2.01290684510345,2.28967161860006,0.697530179667968,1.42961764504609,0.277919071463436,0.527900157202307,0.48326067760608,3.378874920748,2.0605222900061,0.655866665378157,0.194592042883812,0.950487230713254,-0.0256293897909067,-0.165499759192418,0.337438377591738,0.12912080614268,0.649914734765327,1.75994979405817,0.316606620446833,0.9594151266325,2.07540211653817,0.632058942926836,0.310654689834002,0.676698422523063,1.51889660423854,2.41763812677591,0.391005753107211,0.230303626560794,-0.0851486959192092,1.87601244100836,2.17063300634346,0.554683844960043,-0.0583650081614733,0.780857208247592,1.64983907772081,2.93843205539856,1.62007942465666,1.01000653684156,1.12011725317892,1.7272141756876,1.56353608383477,0.703482110280799,1.66174293894647,0.0249620204181501,2.12301756144081,0.37314996126872,1.08440566950193,0.566587706185703,1.63793521649515,0.62313104700759,0.911799681729858,0.25708731431853,0.989174779696651,3.17650927991177,2.63785955945063,0.828472653150234,0.646938769458912,1.56353608383477,1.34331465116005,0.584443498024194,-0.659510000057329,1.89982016345968,1.53377643077062,1.00107864092231,1.27784341441892,1.89982016345968,0.670746491910233,0.191616077577397,0.507068400057401,1.06952584296986,1.60222363281817,2.83129730436761,1.49806484709364,0.36124610004306,3.63183197179328,0.414813475558532,1.60519959812458,1.5694880144476,2.74499431048158,2.61107587169289,0.655866665378157,1.33438675524081,1.77185365528383,-0.461310710650081,-0.150619932660342,1.03381425929288,1.03679022459929,1.92660385121742,1.25998762258043,0.917751612342688,0.0844813265464526,1.48318502056156,0.539804018427967,1.15285287154948,1.13202111440458,0.197568008190228,0.760025451102687,0.774905277634762,1.13499707971099,1.81351716957364,0.968343022551746,1.33438675524081,4.28356837389819,1.08142970419552,0.441597163316268,1.38795413075628,0.596347359249854,1.07547777358269,1.16475673277514,1.66471890425288,-0.0375332510165674,3.10211014725139,0.310654689834002,0.179712216351737,0.194592042883812,1.03976618990571,1.58436784097968,2.92950415947931,1.33141078993439,1.57543994506043,-0.0881246612256246,0.638010873539666,2.13789738797289,1.75102189813892,1.42068974912684,0.578491567411364,2.30157547982572],"y":[2.10767181755745,-0.146619958208497,0.854222318593395,1.98783916947293,0.612639700055007,1.26213265267309,0.509104292109984,-0.0210353430159227,1.27890922340493,3.99192037603841,-0.605339335076031,0.595863129323175,0.439601356220964,-0.191677033888276,2.02330963330595,2.06309407247001,0.0920866767758621,0.988434884448055,1.27028127274284,1.71749671539426,0.207605349529337,0.945774461729966,0.542178102981311,1.3503294816633,0.347090551899716,1.7318766331644,-0.111628824967818,1.63505185351211,2.02954093100635,1.37381668068786,1.61491996863391,1.22330687469371,1.28801650465935,1.18112578256796,-1.18973919325461,1.10635021016322,-0.305278384272399,0.623664303678783,2.16662948041503,0.451584621029415,0.482261778939052,2.21600053142586,1.09484627594711,-0.0473985255945167,-0.00473810287642824,0.554640698382101,0.414676165419384,2.01324369086685,0.624143634271121,0.14481304193305,-0.01672136768488,1.8426019999945,0.0273770468102224,0.051343576427126,0.51006295329466,2.37705561045145,1.79946224668407,-0.138950668731088,0.208564010714013,0.300595484442923,1.45386488960832,0.0594921964968734,1.18927440263771,0.659614098104138,0.226299242630522,0.21431597782207,1.75152918745026,3.30072566188691,0.950088437061009,2.22127316794157,-0.226668167128955,0.263687028832892,1.47687275804055,0.514856259218041,0.232530540330917,1.4145597810366,0.51245960625635,0.129474462978232,0.595863129323175,-0.261179969777296,0.303471467996952,0.0384016504339982,0.854222318593395,0.412758843050032,-0.219478208243884,1.95955866452499,0.587714509253427,-0.193594356257628,1.03924392723589,-0.0373325831554169,1.48981468403368,1.5051532629885,1.25494269378802,1.94517874675484,0.0863347096678053,0.435287380889921,0.391188966394818,2.76387539846827,0.816355201798687,0.894965418942131,0.521087556918436,-0.0895796177202668,0.547930070089368,1.07615238284592,0.376809048624676,2.47819436543478,0.922287262705401,0.290050211411485,-0.378615964900124,0.546012747720015,0.229654556776889,0.0388809810263362,0.489931068416461,0.917493956782021,0.429056083189526,0.610243047093317,0.601135765838894,1.70647211177049,1.10059824305516,0.682621966536366,1.4850213781103,0.209043341306352,0.248827780470411,0.352842519007773,2.04631750173818,2.76435472906061,0.314496071620727,0.764587497826176,0.233489201515593,0.732951678731863,0.81827252416804,1.65805972194434,1.42893969880674,0.511021614479336,-0.724213321975873,-0.20318096810439,-0.221395530613236,0.559434004305482,0.345173229530364,1.4787900804099,-0.307675037234089,-0.24536206023014,1.45338555901598,0.764108167233838,1.10443288779387,-1.01133234678638,1.62929988640406,1.05937581211409,0.542178102981311,-0.0555471456642638,1.25686001615737,0.419469471342765,0.298198831481233,1.0708797463302,0.574293252667962,0.916535295597344,1.00521145517989,0.964468354831151,1.98927716124995,1.78747898187562,0.626540287232811,-0.00953140879980896,0.4702785141306,0.0666821553819445,0.975013627862589,2.09233323860263,0.624143634271121,0.688853264236761,2.7226529675272,-0.0224733347929368,0.530674168765197,1.35704010995603,2.07603599846314,3.02558990188486,0.277587616010696,-0.563158242950281,0.71377845503834,3.01839994299979,1.2396041148332,0.570458607929257,0.645713510926334,1.10922619371725,0.751645571833048,1.76255379107404,0.803892606397898,0.601615096431232,-0.0397292361171073,1.97058326814876,1.17105984012886,1.52192983372033,1.54062372682151,-0.117380792075875,-0.0852656423892241,0.388792313433128,1.17777046842159,0.315934063397741,0.513897598033365,1.52864046201306,1.14277933518091,0.0690788083436348,0.497121027301532,0.70131585963755,0.928039229813458,0.177407522212039,0.820189846537392,0.724803058662116,4.30348526105815,1.85841990954165,0.663928073435181,0.236365185069622,0.326479336429179,3.1947936009802],"z":[2.74820411421215,-0.243675259026272,1.15124202844253,6.04072614732218,-0.86758959617918,1.75252734818575,0.262244915918961,0.477220581311025,2.3877561940435,2.36835989340663,0.0763637014822138,1.4405701796093,0.444893413582895,-0.14831011422829,1.12376393587362,2.12913885221846,0.20728873078114,1.30156335837834,-0.214580808070956,2.85488376771498,-0.127297455205005,1.15124202844253,1.88345237748468,2.20349133799316,-0.90476583906653,1.82041440041482,-0.233977108707833,0.878077461139836,3.00682145603719,1.01708428237079,1.24660717324052,2.2131894883116,3.17169001145065,1.11568214394159,-2.15905994691797,-0.151542831001102,0.150716187256913,0.102225435664718,2.8597328428742,1.35490318512975,1.28055069935505,1.45188468831414,1.6151368853412,0.194357863689888,-0.36490213800676,1.02839879107564,1.28863249128709,-0.0917375707040622,0.779479599569039,0.679265379611837,-0.565330577921165,0.666334512520585,-0.503908959237718,-0.405311097666922,1.37429948576663,4.1043288004072,-0.882136821656839,-0.953256590658724,1.28378341612787,0.192741505303481,1.70565295497996,-0.557248785989133,-0.107901154568127,1.27408526580943,-0.295398727391281,-0.403694739280516,0.398019020377106,1.86567243523421,1.10598399362315,0.603296535450732,3.20240082079238,-0.0109196513837373,0.519245899357593,0.920102779186404,-0.0965866458632811,0.653403645429333,-0.103052079408907,0.936266363050469,0.33659740169366,-0.11598294650016,0.829586709547641,-0.1757882067972,4.64419250146697,-0.707570115924937,-0.739897283653067,1.19973278003473,1.11244942716878,-0.146693755841882,-1.19732670700611,-0.0270832352478022,0.509547749039155,0.247697690441302,-0.0723412700671836,1.93517584584968,0.866762952434991,0.443277055196488,0.49338416517509,3.66144660253182,0.507931390652748,0.160414337575351,0.289723008487871,-0.859507804247148,0.472371506151805,2.99389058894594,0.0440365337540838,0.480453298083837,2.47503954690945,0.831203067934048,0.604912893837138,0.0133257244123602,-2.02490220084623,-2.09763832823452,2.94701619574015,1.17872012101144,0.273559424623806,-0.303480519323313,1.765458215277,0.818272200842796,0.33659740169366,-0.749595433971506,0.326899251375221,-1.0712507528664,-0.0771903452264035,0.0311056666628315,0.36407549426257,-0.245291617412679,0.383471794899448,0.773014166023413,0.270326707850994,-0.133762888750631,0.577434801268227,0.608145610609951,0.987989831415478,0.404484453922732,-0.725350058175409,0.268710349464586,-0.351971270915508,0.509547749039155,-0.052944969430306,-0.109517512954533,-0.641299422082271,-0.539468843738662,0.577434801268227,1.11406578555518,-0.211348091298142,-1.49150393333209,0.108690869210344,0.635623703178862,-0.14346103906907,0.249314048827709,4.29505909000317,0.326899251375221,-0.266304276435963,0.191125146917075,-0.448952774099898,1.25792168194536,-0.497443525692093,1.84950885137014,2.17278052865144,1.27570162419583,-0.398845664121296,-0.471581791509588,0.598447460291512,-0.631601271763832,-0.258222484503931,3.1086520343808,-0.276002426754402,-0.342273120597069,2.02569191548845,-0.684941098515246,-0.524921618261003,0.462673355833366,1.49875908151993,0.556422142244943,0.257395840759741,0.537025841608065,0.165263412734571,-0.0561776862031187,0.21213780594036,0.171728846280197,0.449742488742115,-0.647764855627897,-0.0949702874768748,0.11515630275597,-1.0227600012742,-0.982351041614041,0.176577921439416,-0.419858323144581,-0.96942017452279,0.674416304452617,0.59036566835948,2.87104735157905,0.566120292563382,-0.631601271763832,-0.680092023356027,1.21266364712598,0.0117093660259539,0.181426996598636,1.10598399362315,-1.00013098386451,0.280024858169432,-0.568563294693978,0.414182604241171,0.516013182584781,0.284873933328651,-0.327725895119411,1.92062862037203,0.0456528921404902,-1.35896254564676,-0.531387051806629,-1.10357792059453,1.91739590359921],"type":"scatter3d","mode":"markers","name":"M","marker":{"fillcolor":"rgba(230,159,0,0.5)","color":"rgba(230,159,0,1)","line":{"color":"transparent"}},"frame":null}],"highlight":{"on":"plotly_click","persistent":false,"dynamic":false,"selectize":false,"opacityDim":0.2,"selected":{"opacity":1}},"base_url":"https://plot.ly"},"evals":["config.modeBarButtonsToAdd.0.click"],"jsHooks":{"render":[{"code":"function(el, x) { var ctConfig = crosstalk.var('plotlyCrosstalkOpts').set({\"on\":\"plotly_click\",\"persistent\":false,\"dynamic\":false,\"selectize\":false,\"opacityDim\":0.2,\"selected\":{\"opacity\":1}}); }","data":null}]}}</script><img src="bookdown-demo_files/figure-html/unnamed-chunk-22-2.png" width="672" /></p>
<p>Each attribute can give us new information to help create our classifier. The distance formula for 3-dimensions is <span class="math display">\[Distance = \sqrt{(x_a -x_b)^2 + (y_a - y_b)^2 + (z_a - z_b)^2}\]</span> We can generalize for n-dimensions by</p>
<ul>
<li>summing up the squares of the differences between each individual coordinate</li>
<li>taking the square root of the sum</li>
</ul>
<p>Data source: W.N. Street, W.H. Wolberg and O.L. Mangasarian Nuclear feature extraction for breast tumor diagnosis. IS&amp;T/SPIE 1993 International Symposium on Electronic Imaging: Science and Technology, volume 1905, pages 861-870, San Jose, CA, 1993.</p>
<!-- SECTION about training and testing (remove)
### Training and Testing
Sometimes our classifier might make the wrong prediction. A classifier does not need to be right 100\% of the time to be useful, though we don't want the classifier to make too many wrong predictions. How do we measure the accuracy of a classifier? In order to assess our classifier's performance we need to split our data into a **training** set and a **testing** set. 

* The **training set** is used to build the classifer.  
* The **testing set** is used to measure the accuracy of the classifier. The testing set contains observations whose true class is known so that can try out our classifier and see what proportion of time the classifier was correct. The proportion we find will serve as our *estimate* of the proportion of all new observations whose class our classifier will accurately predict.

![Source: https://www.interworks.com/blog/estam/2017/11/13/my-machine-learning-journey-first-weeks](https://www.interworks.com/sites/default/files/Picture6_11.png "Training and Testing Set")
![A data-flow diagram of training and testing a machine learning model.](https://upload.wikimedia.org/wikipedia/commons/0/09/Supervised_machine_learning_in_a_nutshell.svg "Supervised machine learning data flow")


Here we will make use of the `caret` (Classification And REgression Training) package in R, which contains a set of tools to help the process of making predictive models. We can use the function `names(getModelInfo())` to see a full list of the algorithms `caret` has to offer. 

```r
library(class)
library(caret)
```
In order to create our training and our testing set, we will randomly select 2/3 of the observations to be a part of the training set and the remaining 1/3 of the observations we will reserve for the testing set. We can use the function `createDataPartition` to partition the data. For this function, if the `y` argument is a factor, the random sampling occurs within each class and should preserve the distribution of the class variable.

```r
set.seed(1234)

index <- createDataPartition(bcDat$Class, p=0.66, list=FALSE) #### NOT SURE HOW TO RUN WITH PIPE?

# Subset training set with index
training.data <- bcDat[index,]

# Subset test set with index
test.data <- bcDat[-index,]

training.data %>%
  group_by(Class) %>%
  summarize(n = n()) %>%
  mutate(freq = n / sum(n))
```

```
## # A tibble: 2 x 3
##   Class     n  freq
##   <fct> <int> <dbl>
## 1 B       236 0.628
## 2 M       140 0.372
```

We have 376 observations in our training set. We can draw a scatter plot to visualize the relationship between worst perimeter and worst concavity for our training data.

```r
 training.data %>%  
  ggplot(aes(x=Perimeter, y=Concavity, color = Class)) + 
 # scale_x_continuous(name = "Clump Thickness", breaks=seq(0,10,1)) +
#  scale_y_continuous(name = "Uniformity of Cell Size", breaks=seq(0,10,1)) +
  geom_point() + 
  scale_color_manual(values=c(cbPalette[3], cbPalette[4]))
```

<img src="bookdown-demo_files/figure-html/unnamed-chunk-25-1.png" width="672" />


### K-Nearest Neighbours in R 
We will implement the k-nearest neighbour algorithm in R. 

```r
train.label=bcDat$Class[index]
test.label=bcDat$Class[-index]

# Train a model
model_knn <- train(x = data.frame(training.data[,c(3:ncol(training.data))]), y = train.label, method='knn', preProcess=c("center", "scale"))
### I get an error message: "Setting row names on a tibble is deprecated." when not a data.frame? 

# Predict the labels of the test set
predictions<-predict(object=model_knn, test.data[,c(3:ncol(bcDat))])
```

We used the training data to teach our classifier. Now we have predictions for each row in the test data. Let's take a look at a subset of the actual class of the test data and the corresponding prediction made by the classifier. We can see in row 20 and 34 our classifier classified a malignant observation as benign.

```r
data.frame(ID = test.data$ID, Class = test.data$Class, Prediction = predictions)[19:34,]
```

```
##          ID Class Prediction
## 19   854268     M          M
## 20   855133     M          B
## 21   855138     M          M
## 22 85638502     M          M
## 23   857155     B          B
## 24   857343     B          B
## 25   857373     B          B
## 26 85759902     B          B
## 27   857810     B          B
## 28   858986     M          M
## 29   859471     B          M
## 30  8610908     B          B
## 31  8611555     M          M
## 32 86135501     M          M
## 33 86135502     M          M
## 34   861799     M          B
```

Let's see how the classifier did overall: 

```r
# Evaluate the predictions
table(Prediction = predictions, Class = test.data$Class) 
```

```
##           Class
## Prediction   B   M
##          B 120   6
##          M   1  66
```
We can see from the contingency table above that the classifier made 7 wrong predictions. It predicted 6 malignant observations as benign and 1 benign observation as malignant.

```r
# Confusion matrix 
confusionMatrix(predictions,test.label)
```

```
## Confusion Matrix and Statistics
## 
##           Reference
## Prediction   B   M
##          B 120   6
##          M   1  66
##                                           
##                Accuracy : 0.9637          
##                  95% CI : (0.9267, 0.9853)
##     No Information Rate : 0.6269          
##     P-Value [Acc > NIR] : <2e-16          
##                                           
##                   Kappa : 0.9214          
##  Mcnemar's Test P-Value : 0.1306          
##                                           
##             Sensitivity : 0.9917          
##             Specificity : 0.9167          
##          Pos Pred Value : 0.9524          
##          Neg Pred Value : 0.9851          
##              Prevalence : 0.6269          
##          Detection Rate : 0.6218          
##    Detection Prevalence : 0.6528          
##       Balanced Accuracy : 0.9542          
##                                           
##        'Positive' Class : B               
## 
```
-->
<!-- 

```r
# Train the model with preprocessing
#model_knn <- train(training.data[, 2:10], train.label, method='knn', preProcess=c("center", "scale"))

# Predict the labels of the test set
#predictions<-predict(object=model_knn, test.data[,2:10])

# Evaluate the predictions
#table(predictions)

# Confusion matrix 
#confusionMatrix(predictions,test.label)
```

Data Source
Source:

Creators: 

1. Dr. William H. Wolberg, General Surgery Dept. 
University of Wisconsin, Clinical Sciences Center 
Madison, WI 53792 
wolberg '@' eagle.surgery.wisc.edu 

2. W. Nick Street, Computer Sciences Dept. 
University of Wisconsin, 1210 West Dayton St., Madison, WI 53706 
street '@' cs.wisc.edu 608-262-6619 

3. Olvi L. Mangasarian, Computer Sciences Dept. 
University of Wisconsin, 1210 West Dayton St., Madison, WI 53706 
olvi '@' cs.wisc.edu 

https://www.inferentialthinking.com/chapters/16/1/nearest-neighbors.html
https://www.datacamp.com/community/tutorials/machine-learning-in-r

https://topepo.github.io/caret/data-splitting.html
-->
<!-- SCALING SECTION (REMOVE)
For a k nearest neighbour (knn) classifier, the scale of the variables matter. Since the knn classifier predicts classes by identifying observations that are nearest to it, any variables that are on a large scale will have a much larger effect than variables on a small scale. For example, suppose your dataset has two attributes: salary (in dollars) and years of education. For the knn classifier, a difference of \$1000 is huge compared to a difference of 10 years of education. So salary’s influence on the distance function will usually overpower the influence of years of education. Therefore we need to standardize our variables so that our variables will be on a comparable scale. We can do this with the `scale()` function in R. 


```r
scaled <- bcDat %>% 
  select(-c(ID,Class)) %>% 
  scale() 

bcDat_scaled <- data.frame(ID = bcDat$ID, Class = bcDat$Class, scaled)
#summary(bcDat_scaled)
```

Now that we've standardized our data, we can make a scatterplot of the standardized worst perimeter and worst concavity variables. 

```r
p <- bcDat_scaled %>%  
  ggplot(aes(x=Perimeter, y=Concavity, color = Class)) + 
  geom_point() +
  scale_x_continuous(name = "Perimeter", breaks = seq(-2,4, 1))+
  scale_y_continuous(name = "Concavity", breaks = seq(-2,4, 1)) +
  scale_color_manual(values=c(cbPalette[3], cbPalette[4]))
p
```

<img src="bookdown-demo_files/figure-html/unnamed-chunk-32-1.png" width="672" />
-->

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="chapter5.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="chapter7.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/05-classification-part1.Rmd",
"text": "Edit"
},
"download": ["bookdown-demo.pdf", "bookdown-demo.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
